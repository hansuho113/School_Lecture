{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "기계학습_12주차_1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNMAAZ2N+9A07iuLc4KjdMC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hansuho113/Machine_learning/blob/main/%EA%B8%B0%EA%B3%84%ED%95%99%EC%8A%B5_12%EC%A3%BC%EC%B0%A8_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9i_ZHm7CCWk",
        "outputId": "d4dee417-34af-44bb-c114-91614283f8c2"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "a = tf.random.uniform([2, 3], 0, 1) # [0, 1] 사이의 2*3 행렬 생성\n",
        "print(a, type(a))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0.6370065  0.07501495 0.17547691]\n",
            " [0.8525187  0.86503625 0.9818268 ]], shape=(2, 3), dtype=float32) <class 'tensorflow.python.framework.ops.EagerTensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30LI7gh6CVku"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "t = tf.random.uniform([2, 3], 0, 1)\n",
        "n = np.random.uniform(0, 1, [2,3])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3CrE9GkC6vx",
        "outputId": "90810317-c09a-4679-f217-b716a7dc6f74"
      },
      "source": [
        "print(t)\n",
        "print(n)\n",
        "\n",
        "print(t+n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0.6574092  0.61094666 0.8248675 ]\n",
            " [0.7676804  0.95748866 0.47046804]], shape=(2, 3), dtype=float32)\n",
            "[[0.59244814 0.22532169 0.21421251]\n",
            " [0.93520794 0.38312047 0.10610454]]\n",
            "tf.Tensor(\n",
            "[[1.2498573  0.83626837 1.03908   ]\n",
            " [1.7028884  1.3406091  0.5765726 ]], shape=(2, 3), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XgbEBTiC9pV",
        "outputId": "2fc0eb6c-a24e-4de1-9dfe-61b1ae20f077"
      },
      "source": [
        "import tensorflow.keras.datasets as ds\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = ds.mnist.load_data()\n",
        "yy_train = tf.one_hot(y_train, 10, dtype=tf.int8)\n",
        "print(\"mnist:\", x_train.shape, y_train.shape, yy_train.shape)\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = ds.cifar10.load_data()\n",
        "yy_train = tf.one_hot(y_train, 10, dtype=tf.int8)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mnist: (60000, 28, 28) (60000,) (60000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Kh9oAnsDY6n",
        "outputId": "f8af8a29-1d18-428b-be8d-635392add3a9"
      },
      "source": [
        "x = [[0.0,0.0],[0.0,1.0],[1.0,0.0],[1.0,1.0]]\n",
        "y = [[-1],[1],[1],[1]]\n",
        "\n",
        "w = tf.Variable([[1.0], [1.0]])\n",
        "b = tf.Variable(-0.5)\n",
        "\n",
        "s = tf.add(tf.matmul(x, w), b)\n",
        "o = tf.sign(s)\n",
        "\n",
        "print(o)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[-1.]\n",
            " [ 1.]\n",
            " [ 1.]\n",
            " [ 1.]], shape=(4, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ly5NFH7oEaab",
        "outputId": "e142f7d6-aa5a-4b1c-ac5b-c4def25fe840"
      },
      "source": [
        "w = tf.Variable(tf.random.uniform([2, 1], -0.5, 0.5))\n",
        "b = tf.Variable(tf.zeros([1]))\n",
        "\n",
        "opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
        "\n",
        "def forward():\n",
        "    s = tf.add(tf.matmul(x, w), b)\n",
        "    o = tf.tanh(s)\n",
        "    return o\n",
        "\n",
        "def loss():\n",
        "    o = forward()\n",
        "    return tf.reduce_mean((y-o)**2)\n",
        "\n",
        "for i in range(500):\n",
        "    opt.minimize(loss, var_list = [w, b])\n",
        "    if(i%100 == 0):\n",
        "        print(f\"loss at epoch {i} = {loss().numpy()}\")\n",
        "\n",
        "o = forward()\n",
        "print(o)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss at epoch 0 = 0.7895994186401367\n",
            "loss at epoch 100 = 0.09255778789520264\n",
            "loss at epoch 200 = 0.04252049699425697\n",
            "loss at epoch 300 = 0.026684263721108437\n",
            "loss at epoch 400 = 0.019200799986720085\n",
            "tf.Tensor(\n",
            "[[-0.81602913]\n",
            " [ 0.8861962 ]\n",
            " [ 0.8861869 ]\n",
            " [ 0.9992627 ]], shape=(4, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbhfBAR6FJgB",
        "outputId": "e9ea9d30-b4c6-4420-fbe5-07deff6c88f7"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "n_input = 2\n",
        "n_output=1\n",
        "perceptron = Sequential()\n",
        "perceptron.add(Dense(units=n_output,\n",
        "                     activation='tanh',\n",
        "                     input_shape=(n_input,),\n",
        "                     kernel_initializer = 'randon_uniform',\n",
        "                     bias_initializer='zeros'))\n",
        "\n",
        "perceptron.compile(loss='mse',\n",
        "                   optimizer=SGD(learning_rate=0.1),\n",
        "                   metrics=['mse'])\n",
        "\n",
        "perceptron.fit(x, y, epochs=500, verbose=2)\n",
        "res = perceptron.predict(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "1/1 - 0s - loss: 1.0163 - mse: 1.0163\n",
            "Epoch 2/500\n",
            "1/1 - 0s - loss: 0.7590 - mse: 0.7590\n",
            "Epoch 3/500\n",
            "1/1 - 0s - loss: 0.6458 - mse: 0.6458\n",
            "Epoch 4/500\n",
            "1/1 - 0s - loss: 0.5907 - mse: 0.5907\n",
            "Epoch 5/500\n",
            "1/1 - 0s - loss: 0.5577 - mse: 0.5577\n",
            "Epoch 6/500\n",
            "1/1 - 0s - loss: 0.5341 - mse: 0.5341\n",
            "Epoch 7/500\n",
            "1/1 - 0s - loss: 0.5152 - mse: 0.5152\n",
            "Epoch 8/500\n",
            "1/1 - 0s - loss: 0.4988 - mse: 0.4988\n",
            "Epoch 9/500\n",
            "1/1 - 0s - loss: 0.4840 - mse: 0.4840\n",
            "Epoch 10/500\n",
            "1/1 - 0s - loss: 0.4701 - mse: 0.4701\n",
            "Epoch 11/500\n",
            "1/1 - 0s - loss: 0.4570 - mse: 0.4570\n",
            "Epoch 12/500\n",
            "1/1 - 0s - loss: 0.4444 - mse: 0.4444\n",
            "Epoch 13/500\n",
            "1/1 - 0s - loss: 0.4323 - mse: 0.4323\n",
            "Epoch 14/500\n",
            "1/1 - 0s - loss: 0.4207 - mse: 0.4207\n",
            "Epoch 15/500\n",
            "1/1 - 0s - loss: 0.4095 - mse: 0.4095\n",
            "Epoch 16/500\n",
            "1/1 - 0s - loss: 0.3986 - mse: 0.3986\n",
            "Epoch 17/500\n",
            "1/1 - 0s - loss: 0.3882 - mse: 0.3882\n",
            "Epoch 18/500\n",
            "1/1 - 0s - loss: 0.3781 - mse: 0.3781\n",
            "Epoch 19/500\n",
            "1/1 - 0s - loss: 0.3683 - mse: 0.3683\n",
            "Epoch 20/500\n",
            "1/1 - 0s - loss: 0.3589 - mse: 0.3589\n",
            "Epoch 21/500\n",
            "1/1 - 0s - loss: 0.3499 - mse: 0.3499\n",
            "Epoch 22/500\n",
            "1/1 - 0s - loss: 0.3411 - mse: 0.3411\n",
            "Epoch 23/500\n",
            "1/1 - 0s - loss: 0.3327 - mse: 0.3327\n",
            "Epoch 24/500\n",
            "1/1 - 0s - loss: 0.3246 - mse: 0.3246\n",
            "Epoch 25/500\n",
            "1/1 - 0s - loss: 0.3168 - mse: 0.3168\n",
            "Epoch 26/500\n",
            "1/1 - 0s - loss: 0.3092 - mse: 0.3092\n",
            "Epoch 27/500\n",
            "1/1 - 0s - loss: 0.3019 - mse: 0.3019\n",
            "Epoch 28/500\n",
            "1/1 - 0s - loss: 0.2949 - mse: 0.2949\n",
            "Epoch 29/500\n",
            "1/1 - 0s - loss: 0.2882 - mse: 0.2882\n",
            "Epoch 30/500\n",
            "1/1 - 0s - loss: 0.2816 - mse: 0.2816\n",
            "Epoch 31/500\n",
            "1/1 - 0s - loss: 0.2753 - mse: 0.2753\n",
            "Epoch 32/500\n",
            "1/1 - 0s - loss: 0.2692 - mse: 0.2692\n",
            "Epoch 33/500\n",
            "1/1 - 0s - loss: 0.2633 - mse: 0.2633\n",
            "Epoch 34/500\n",
            "1/1 - 0s - loss: 0.2577 - mse: 0.2577\n",
            "Epoch 35/500\n",
            "1/1 - 0s - loss: 0.2522 - mse: 0.2522\n",
            "Epoch 36/500\n",
            "1/1 - 0s - loss: 0.2469 - mse: 0.2469\n",
            "Epoch 37/500\n",
            "1/1 - 0s - loss: 0.2418 - mse: 0.2418\n",
            "Epoch 38/500\n",
            "1/1 - 0s - loss: 0.2368 - mse: 0.2368\n",
            "Epoch 39/500\n",
            "1/1 - 0s - loss: 0.2320 - mse: 0.2320\n",
            "Epoch 40/500\n",
            "1/1 - 0s - loss: 0.2274 - mse: 0.2274\n",
            "Epoch 41/500\n",
            "1/1 - 0s - loss: 0.2229 - mse: 0.2229\n",
            "Epoch 42/500\n",
            "1/1 - 0s - loss: 0.2185 - mse: 0.2185\n",
            "Epoch 43/500\n",
            "1/1 - 0s - loss: 0.2143 - mse: 0.2143\n",
            "Epoch 44/500\n",
            "1/1 - 0s - loss: 0.2102 - mse: 0.2102\n",
            "Epoch 45/500\n",
            "1/1 - 0s - loss: 0.2062 - mse: 0.2062\n",
            "Epoch 46/500\n",
            "1/1 - 0s - loss: 0.2024 - mse: 0.2024\n",
            "Epoch 47/500\n",
            "1/1 - 0s - loss: 0.1987 - mse: 0.1987\n",
            "Epoch 48/500\n",
            "1/1 - 0s - loss: 0.1951 - mse: 0.1951\n",
            "Epoch 49/500\n",
            "1/1 - 0s - loss: 0.1916 - mse: 0.1916\n",
            "Epoch 50/500\n",
            "1/1 - 0s - loss: 0.1882 - mse: 0.1882\n",
            "Epoch 51/500\n",
            "1/1 - 0s - loss: 0.1849 - mse: 0.1849\n",
            "Epoch 52/500\n",
            "1/1 - 0s - loss: 0.1816 - mse: 0.1816\n",
            "Epoch 53/500\n",
            "1/1 - 0s - loss: 0.1785 - mse: 0.1785\n",
            "Epoch 54/500\n",
            "1/1 - 0s - loss: 0.1755 - mse: 0.1755\n",
            "Epoch 55/500\n",
            "1/1 - 0s - loss: 0.1725 - mse: 0.1725\n",
            "Epoch 56/500\n",
            "1/1 - 0s - loss: 0.1697 - mse: 0.1697\n",
            "Epoch 57/500\n",
            "1/1 - 0s - loss: 0.1669 - mse: 0.1669\n",
            "Epoch 58/500\n",
            "1/1 - 0s - loss: 0.1642 - mse: 0.1642\n",
            "Epoch 59/500\n",
            "1/1 - 0s - loss: 0.1615 - mse: 0.1615\n",
            "Epoch 60/500\n",
            "1/1 - 0s - loss: 0.1590 - mse: 0.1590\n",
            "Epoch 61/500\n",
            "1/1 - 0s - loss: 0.1565 - mse: 0.1565\n",
            "Epoch 62/500\n",
            "1/1 - 0s - loss: 0.1540 - mse: 0.1540\n",
            "Epoch 63/500\n",
            "1/1 - 0s - loss: 0.1517 - mse: 0.1517\n",
            "Epoch 64/500\n",
            "1/1 - 0s - loss: 0.1494 - mse: 0.1494\n",
            "Epoch 65/500\n",
            "1/1 - 0s - loss: 0.1471 - mse: 0.1471\n",
            "Epoch 66/500\n",
            "1/1 - 0s - loss: 0.1449 - mse: 0.1449\n",
            "Epoch 67/500\n",
            "1/1 - 0s - loss: 0.1428 - mse: 0.1428\n",
            "Epoch 68/500\n",
            "1/1 - 0s - loss: 0.1407 - mse: 0.1407\n",
            "Epoch 69/500\n",
            "1/1 - 0s - loss: 0.1386 - mse: 0.1386\n",
            "Epoch 70/500\n",
            "1/1 - 0s - loss: 0.1367 - mse: 0.1367\n",
            "Epoch 71/500\n",
            "1/1 - 0s - loss: 0.1347 - mse: 0.1347\n",
            "Epoch 72/500\n",
            "1/1 - 0s - loss: 0.1328 - mse: 0.1328\n",
            "Epoch 73/500\n",
            "1/1 - 0s - loss: 0.1310 - mse: 0.1310\n",
            "Epoch 74/500\n",
            "1/1 - 0s - loss: 0.1292 - mse: 0.1292\n",
            "Epoch 75/500\n",
            "1/1 - 0s - loss: 0.1274 - mse: 0.1274\n",
            "Epoch 76/500\n",
            "1/1 - 0s - loss: 0.1257 - mse: 0.1257\n",
            "Epoch 77/500\n",
            "1/1 - 0s - loss: 0.1240 - mse: 0.1240\n",
            "Epoch 78/500\n",
            "1/1 - 0s - loss: 0.1224 - mse: 0.1224\n",
            "Epoch 79/500\n",
            "1/1 - 0s - loss: 0.1208 - mse: 0.1208\n",
            "Epoch 80/500\n",
            "1/1 - 0s - loss: 0.1192 - mse: 0.1192\n",
            "Epoch 81/500\n",
            "1/1 - 0s - loss: 0.1177 - mse: 0.1177\n",
            "Epoch 82/500\n",
            "1/1 - 0s - loss: 0.1162 - mse: 0.1162\n",
            "Epoch 83/500\n",
            "1/1 - 0s - loss: 0.1147 - mse: 0.1147\n",
            "Epoch 84/500\n",
            "1/1 - 0s - loss: 0.1133 - mse: 0.1133\n",
            "Epoch 85/500\n",
            "1/1 - 0s - loss: 0.1119 - mse: 0.1119\n",
            "Epoch 86/500\n",
            "1/1 - 0s - loss: 0.1105 - mse: 0.1105\n",
            "Epoch 87/500\n",
            "1/1 - 0s - loss: 0.1091 - mse: 0.1091\n",
            "Epoch 88/500\n",
            "1/1 - 0s - loss: 0.1078 - mse: 0.1078\n",
            "Epoch 89/500\n",
            "1/1 - 0s - loss: 0.1065 - mse: 0.1065\n",
            "Epoch 90/500\n",
            "1/1 - 0s - loss: 0.1053 - mse: 0.1053\n",
            "Epoch 91/500\n",
            "1/1 - 0s - loss: 0.1040 - mse: 0.1040\n",
            "Epoch 92/500\n",
            "1/1 - 0s - loss: 0.1028 - mse: 0.1028\n",
            "Epoch 93/500\n",
            "1/1 - 0s - loss: 0.1016 - mse: 0.1016\n",
            "Epoch 94/500\n",
            "1/1 - 0s - loss: 0.1005 - mse: 0.1005\n",
            "Epoch 95/500\n",
            "1/1 - 0s - loss: 0.0993 - mse: 0.0993\n",
            "Epoch 96/500\n",
            "1/1 - 0s - loss: 0.0982 - mse: 0.0982\n",
            "Epoch 97/500\n",
            "1/1 - 0s - loss: 0.0971 - mse: 0.0971\n",
            "Epoch 98/500\n",
            "1/1 - 0s - loss: 0.0960 - mse: 0.0960\n",
            "Epoch 99/500\n",
            "1/1 - 0s - loss: 0.0950 - mse: 0.0950\n",
            "Epoch 100/500\n",
            "1/1 - 0s - loss: 0.0939 - mse: 0.0939\n",
            "Epoch 101/500\n",
            "1/1 - 0s - loss: 0.0929 - mse: 0.0929\n",
            "Epoch 102/500\n",
            "1/1 - 0s - loss: 0.0919 - mse: 0.0919\n",
            "Epoch 103/500\n",
            "1/1 - 0s - loss: 0.0910 - mse: 0.0910\n",
            "Epoch 104/500\n",
            "1/1 - 0s - loss: 0.0900 - mse: 0.0900\n",
            "Epoch 105/500\n",
            "1/1 - 0s - loss: 0.0891 - mse: 0.0891\n",
            "Epoch 106/500\n",
            "1/1 - 0s - loss: 0.0881 - mse: 0.0881\n",
            "Epoch 107/500\n",
            "1/1 - 0s - loss: 0.0872 - mse: 0.0872\n",
            "Epoch 108/500\n",
            "1/1 - 0s - loss: 0.0863 - mse: 0.0863\n",
            "Epoch 109/500\n",
            "1/1 - 0s - loss: 0.0855 - mse: 0.0855\n",
            "Epoch 110/500\n",
            "1/1 - 0s - loss: 0.0846 - mse: 0.0846\n",
            "Epoch 111/500\n",
            "1/1 - 0s - loss: 0.0838 - mse: 0.0838\n",
            "Epoch 112/500\n",
            "1/1 - 0s - loss: 0.0829 - mse: 0.0829\n",
            "Epoch 113/500\n",
            "1/1 - 0s - loss: 0.0821 - mse: 0.0821\n",
            "Epoch 114/500\n",
            "1/1 - 0s - loss: 0.0813 - mse: 0.0813\n",
            "Epoch 115/500\n",
            "1/1 - 0s - loss: 0.0805 - mse: 0.0805\n",
            "Epoch 116/500\n",
            "1/1 - 0s - loss: 0.0798 - mse: 0.0798\n",
            "Epoch 117/500\n",
            "1/1 - 0s - loss: 0.0790 - mse: 0.0790\n",
            "Epoch 118/500\n",
            "1/1 - 0s - loss: 0.0782 - mse: 0.0782\n",
            "Epoch 119/500\n",
            "1/1 - 0s - loss: 0.0775 - mse: 0.0775\n",
            "Epoch 120/500\n",
            "1/1 - 0s - loss: 0.0768 - mse: 0.0768\n",
            "Epoch 121/500\n",
            "1/1 - 0s - loss: 0.0761 - mse: 0.0761\n",
            "Epoch 122/500\n",
            "1/1 - 0s - loss: 0.0754 - mse: 0.0754\n",
            "Epoch 123/500\n",
            "1/1 - 0s - loss: 0.0747 - mse: 0.0747\n",
            "Epoch 124/500\n",
            "1/1 - 0s - loss: 0.0740 - mse: 0.0740\n",
            "Epoch 125/500\n",
            "1/1 - 0s - loss: 0.0734 - mse: 0.0734\n",
            "Epoch 126/500\n",
            "1/1 - 0s - loss: 0.0727 - mse: 0.0727\n",
            "Epoch 127/500\n",
            "1/1 - 0s - loss: 0.0721 - mse: 0.0721\n",
            "Epoch 128/500\n",
            "1/1 - 0s - loss: 0.0714 - mse: 0.0714\n",
            "Epoch 129/500\n",
            "1/1 - 0s - loss: 0.0708 - mse: 0.0708\n",
            "Epoch 130/500\n",
            "1/1 - 0s - loss: 0.0702 - mse: 0.0702\n",
            "Epoch 131/500\n",
            "1/1 - 0s - loss: 0.0696 - mse: 0.0696\n",
            "Epoch 132/500\n",
            "1/1 - 0s - loss: 0.0690 - mse: 0.0690\n",
            "Epoch 133/500\n",
            "1/1 - 0s - loss: 0.0684 - mse: 0.0684\n",
            "Epoch 134/500\n",
            "1/1 - 0s - loss: 0.0678 - mse: 0.0678\n",
            "Epoch 135/500\n",
            "1/1 - 0s - loss: 0.0673 - mse: 0.0673\n",
            "Epoch 136/500\n",
            "1/1 - 0s - loss: 0.0667 - mse: 0.0667\n",
            "Epoch 137/500\n",
            "1/1 - 0s - loss: 0.0661 - mse: 0.0661\n",
            "Epoch 138/500\n",
            "1/1 - 0s - loss: 0.0656 - mse: 0.0656\n",
            "Epoch 139/500\n",
            "1/1 - 0s - loss: 0.0651 - mse: 0.0651\n",
            "Epoch 140/500\n",
            "1/1 - 0s - loss: 0.0645 - mse: 0.0645\n",
            "Epoch 141/500\n",
            "1/1 - 0s - loss: 0.0640 - mse: 0.0640\n",
            "Epoch 142/500\n",
            "1/1 - 0s - loss: 0.0635 - mse: 0.0635\n",
            "Epoch 143/500\n",
            "1/1 - 0s - loss: 0.0630 - mse: 0.0630\n",
            "Epoch 144/500\n",
            "1/1 - 0s - loss: 0.0625 - mse: 0.0625\n",
            "Epoch 145/500\n",
            "1/1 - 0s - loss: 0.0620 - mse: 0.0620\n",
            "Epoch 146/500\n",
            "1/1 - 0s - loss: 0.0615 - mse: 0.0615\n",
            "Epoch 147/500\n",
            "1/1 - 0s - loss: 0.0610 - mse: 0.0610\n",
            "Epoch 148/500\n",
            "1/1 - 0s - loss: 0.0606 - mse: 0.0606\n",
            "Epoch 149/500\n",
            "1/1 - 0s - loss: 0.0601 - mse: 0.0601\n",
            "Epoch 150/500\n",
            "1/1 - 0s - loss: 0.0597 - mse: 0.0597\n",
            "Epoch 151/500\n",
            "1/1 - 0s - loss: 0.0592 - mse: 0.0592\n",
            "Epoch 152/500\n",
            "1/1 - 0s - loss: 0.0588 - mse: 0.0588\n",
            "Epoch 153/500\n",
            "1/1 - 0s - loss: 0.0583 - mse: 0.0583\n",
            "Epoch 154/500\n",
            "1/1 - 0s - loss: 0.0579 - mse: 0.0579\n",
            "Epoch 155/500\n",
            "1/1 - 0s - loss: 0.0575 - mse: 0.0575\n",
            "Epoch 156/500\n",
            "1/1 - 0s - loss: 0.0570 - mse: 0.0570\n",
            "Epoch 157/500\n",
            "1/1 - 0s - loss: 0.0566 - mse: 0.0566\n",
            "Epoch 158/500\n",
            "1/1 - 0s - loss: 0.0562 - mse: 0.0562\n",
            "Epoch 159/500\n",
            "1/1 - 0s - loss: 0.0558 - mse: 0.0558\n",
            "Epoch 160/500\n",
            "1/1 - 0s - loss: 0.0554 - mse: 0.0554\n",
            "Epoch 161/500\n",
            "1/1 - 0s - loss: 0.0550 - mse: 0.0550\n",
            "Epoch 162/500\n",
            "1/1 - 0s - loss: 0.0546 - mse: 0.0546\n",
            "Epoch 163/500\n",
            "1/1 - 0s - loss: 0.0542 - mse: 0.0542\n",
            "Epoch 164/500\n",
            "1/1 - 0s - loss: 0.0539 - mse: 0.0539\n",
            "Epoch 165/500\n",
            "1/1 - 0s - loss: 0.0535 - mse: 0.0535\n",
            "Epoch 166/500\n",
            "1/1 - 0s - loss: 0.0531 - mse: 0.0531\n",
            "Epoch 167/500\n",
            "1/1 - 0s - loss: 0.0528 - mse: 0.0528\n",
            "Epoch 168/500\n",
            "1/1 - 0s - loss: 0.0524 - mse: 0.0524\n",
            "Epoch 169/500\n",
            "1/1 - 0s - loss: 0.0520 - mse: 0.0520\n",
            "Epoch 170/500\n",
            "1/1 - 0s - loss: 0.0517 - mse: 0.0517\n",
            "Epoch 171/500\n",
            "1/1 - 0s - loss: 0.0513 - mse: 0.0513\n",
            "Epoch 172/500\n",
            "1/1 - 0s - loss: 0.0510 - mse: 0.0510\n",
            "Epoch 173/500\n",
            "1/1 - 0s - loss: 0.0507 - mse: 0.0507\n",
            "Epoch 174/500\n",
            "1/1 - 0s - loss: 0.0503 - mse: 0.0503\n",
            "Epoch 175/500\n",
            "1/1 - 0s - loss: 0.0500 - mse: 0.0500\n",
            "Epoch 176/500\n",
            "1/1 - 0s - loss: 0.0497 - mse: 0.0497\n",
            "Epoch 177/500\n",
            "1/1 - 0s - loss: 0.0493 - mse: 0.0493\n",
            "Epoch 178/500\n",
            "1/1 - 0s - loss: 0.0490 - mse: 0.0490\n",
            "Epoch 179/500\n",
            "1/1 - 0s - loss: 0.0487 - mse: 0.0487\n",
            "Epoch 180/500\n",
            "1/1 - 0s - loss: 0.0484 - mse: 0.0484\n",
            "Epoch 181/500\n",
            "1/1 - 0s - loss: 0.0481 - mse: 0.0481\n",
            "Epoch 182/500\n",
            "1/1 - 0s - loss: 0.0478 - mse: 0.0478\n",
            "Epoch 183/500\n",
            "1/1 - 0s - loss: 0.0475 - mse: 0.0475\n",
            "Epoch 184/500\n",
            "1/1 - 0s - loss: 0.0472 - mse: 0.0472\n",
            "Epoch 185/500\n",
            "1/1 - 0s - loss: 0.0469 - mse: 0.0469\n",
            "Epoch 186/500\n",
            "1/1 - 0s - loss: 0.0466 - mse: 0.0466\n",
            "Epoch 187/500\n",
            "1/1 - 0s - loss: 0.0463 - mse: 0.0463\n",
            "Epoch 188/500\n",
            "1/1 - 0s - loss: 0.0460 - mse: 0.0460\n",
            "Epoch 189/500\n",
            "1/1 - 0s - loss: 0.0457 - mse: 0.0457\n",
            "Epoch 190/500\n",
            "1/1 - 0s - loss: 0.0455 - mse: 0.0455\n",
            "Epoch 191/500\n",
            "1/1 - 0s - loss: 0.0452 - mse: 0.0452\n",
            "Epoch 192/500\n",
            "1/1 - 0s - loss: 0.0449 - mse: 0.0449\n",
            "Epoch 193/500\n",
            "1/1 - 0s - loss: 0.0447 - mse: 0.0447\n",
            "Epoch 194/500\n",
            "1/1 - 0s - loss: 0.0444 - mse: 0.0444\n",
            "Epoch 195/500\n",
            "1/1 - 0s - loss: 0.0441 - mse: 0.0441\n",
            "Epoch 196/500\n",
            "1/1 - 0s - loss: 0.0439 - mse: 0.0439\n",
            "Epoch 197/500\n",
            "1/1 - 0s - loss: 0.0436 - mse: 0.0436\n",
            "Epoch 198/500\n",
            "1/1 - 0s - loss: 0.0434 - mse: 0.0434\n",
            "Epoch 199/500\n",
            "1/1 - 0s - loss: 0.0431 - mse: 0.0431\n",
            "Epoch 200/500\n",
            "1/1 - 0s - loss: 0.0429 - mse: 0.0429\n",
            "Epoch 201/500\n",
            "1/1 - 0s - loss: 0.0426 - mse: 0.0426\n",
            "Epoch 202/500\n",
            "1/1 - 0s - loss: 0.0424 - mse: 0.0424\n",
            "Epoch 203/500\n",
            "1/1 - 0s - loss: 0.0421 - mse: 0.0421\n",
            "Epoch 204/500\n",
            "1/1 - 0s - loss: 0.0419 - mse: 0.0419\n",
            "Epoch 205/500\n",
            "1/1 - 0s - loss: 0.0417 - mse: 0.0417\n",
            "Epoch 206/500\n",
            "1/1 - 0s - loss: 0.0414 - mse: 0.0414\n",
            "Epoch 207/500\n",
            "1/1 - 0s - loss: 0.0412 - mse: 0.0412\n",
            "Epoch 208/500\n",
            "1/1 - 0s - loss: 0.0410 - mse: 0.0410\n",
            "Epoch 209/500\n",
            "1/1 - 0s - loss: 0.0407 - mse: 0.0407\n",
            "Epoch 210/500\n",
            "1/1 - 0s - loss: 0.0405 - mse: 0.0405\n",
            "Epoch 211/500\n",
            "1/1 - 0s - loss: 0.0403 - mse: 0.0403\n",
            "Epoch 212/500\n",
            "1/1 - 0s - loss: 0.0401 - mse: 0.0401\n",
            "Epoch 213/500\n",
            "1/1 - 0s - loss: 0.0398 - mse: 0.0398\n",
            "Epoch 214/500\n",
            "1/1 - 0s - loss: 0.0396 - mse: 0.0396\n",
            "Epoch 215/500\n",
            "1/1 - 0s - loss: 0.0394 - mse: 0.0394\n",
            "Epoch 216/500\n",
            "1/1 - 0s - loss: 0.0392 - mse: 0.0392\n",
            "Epoch 217/500\n",
            "1/1 - 0s - loss: 0.0390 - mse: 0.0390\n",
            "Epoch 218/500\n",
            "1/1 - 0s - loss: 0.0388 - mse: 0.0388\n",
            "Epoch 219/500\n",
            "1/1 - 0s - loss: 0.0386 - mse: 0.0386\n",
            "Epoch 220/500\n",
            "1/1 - 0s - loss: 0.0384 - mse: 0.0384\n",
            "Epoch 221/500\n",
            "1/1 - 0s - loss: 0.0382 - mse: 0.0382\n",
            "Epoch 222/500\n",
            "1/1 - 0s - loss: 0.0380 - mse: 0.0380\n",
            "Epoch 223/500\n",
            "1/1 - 0s - loss: 0.0378 - mse: 0.0378\n",
            "Epoch 224/500\n",
            "1/1 - 0s - loss: 0.0376 - mse: 0.0376\n",
            "Epoch 225/500\n",
            "1/1 - 0s - loss: 0.0374 - mse: 0.0374\n",
            "Epoch 226/500\n",
            "1/1 - 0s - loss: 0.0372 - mse: 0.0372\n",
            "Epoch 227/500\n",
            "1/1 - 0s - loss: 0.0370 - mse: 0.0370\n",
            "Epoch 228/500\n",
            "1/1 - 0s - loss: 0.0368 - mse: 0.0368\n",
            "Epoch 229/500\n",
            "1/1 - 0s - loss: 0.0366 - mse: 0.0366\n",
            "Epoch 230/500\n",
            "1/1 - 0s - loss: 0.0365 - mse: 0.0365\n",
            "Epoch 231/500\n",
            "1/1 - 0s - loss: 0.0363 - mse: 0.0363\n",
            "Epoch 232/500\n",
            "1/1 - 0s - loss: 0.0361 - mse: 0.0361\n",
            "Epoch 233/500\n",
            "1/1 - 0s - loss: 0.0359 - mse: 0.0359\n",
            "Epoch 234/500\n",
            "1/1 - 0s - loss: 0.0357 - mse: 0.0357\n",
            "Epoch 235/500\n",
            "1/1 - 0s - loss: 0.0356 - mse: 0.0356\n",
            "Epoch 236/500\n",
            "1/1 - 0s - loss: 0.0354 - mse: 0.0354\n",
            "Epoch 237/500\n",
            "1/1 - 0s - loss: 0.0352 - mse: 0.0352\n",
            "Epoch 238/500\n",
            "1/1 - 0s - loss: 0.0350 - mse: 0.0350\n",
            "Epoch 239/500\n",
            "1/1 - 0s - loss: 0.0349 - mse: 0.0349\n",
            "Epoch 240/500\n",
            "1/1 - 0s - loss: 0.0347 - mse: 0.0347\n",
            "Epoch 241/500\n",
            "1/1 - 0s - loss: 0.0345 - mse: 0.0345\n",
            "Epoch 242/500\n",
            "1/1 - 0s - loss: 0.0344 - mse: 0.0344\n",
            "Epoch 243/500\n",
            "1/1 - 0s - loss: 0.0342 - mse: 0.0342\n",
            "Epoch 244/500\n",
            "1/1 - 0s - loss: 0.0341 - mse: 0.0341\n",
            "Epoch 245/500\n",
            "1/1 - 0s - loss: 0.0339 - mse: 0.0339\n",
            "Epoch 246/500\n",
            "1/1 - 0s - loss: 0.0337 - mse: 0.0337\n",
            "Epoch 247/500\n",
            "1/1 - 0s - loss: 0.0336 - mse: 0.0336\n",
            "Epoch 248/500\n",
            "1/1 - 0s - loss: 0.0334 - mse: 0.0334\n",
            "Epoch 249/500\n",
            "1/1 - 0s - loss: 0.0333 - mse: 0.0333\n",
            "Epoch 250/500\n",
            "1/1 - 0s - loss: 0.0331 - mse: 0.0331\n",
            "Epoch 251/500\n",
            "1/1 - 0s - loss: 0.0330 - mse: 0.0330\n",
            "Epoch 252/500\n",
            "1/1 - 0s - loss: 0.0328 - mse: 0.0328\n",
            "Epoch 253/500\n",
            "1/1 - 0s - loss: 0.0327 - mse: 0.0327\n",
            "Epoch 254/500\n",
            "1/1 - 0s - loss: 0.0325 - mse: 0.0325\n",
            "Epoch 255/500\n",
            "1/1 - 0s - loss: 0.0324 - mse: 0.0324\n",
            "Epoch 256/500\n",
            "1/1 - 0s - loss: 0.0322 - mse: 0.0322\n",
            "Epoch 257/500\n",
            "1/1 - 0s - loss: 0.0321 - mse: 0.0321\n",
            "Epoch 258/500\n",
            "1/1 - 0s - loss: 0.0319 - mse: 0.0319\n",
            "Epoch 259/500\n",
            "1/1 - 0s - loss: 0.0318 - mse: 0.0318\n",
            "Epoch 260/500\n",
            "1/1 - 0s - loss: 0.0316 - mse: 0.0316\n",
            "Epoch 261/500\n",
            "1/1 - 0s - loss: 0.0315 - mse: 0.0315\n",
            "Epoch 262/500\n",
            "1/1 - 0s - loss: 0.0314 - mse: 0.0314\n",
            "Epoch 263/500\n",
            "1/1 - 0s - loss: 0.0312 - mse: 0.0312\n",
            "Epoch 264/500\n",
            "1/1 - 0s - loss: 0.0311 - mse: 0.0311\n",
            "Epoch 265/500\n",
            "1/1 - 0s - loss: 0.0310 - mse: 0.0310\n",
            "Epoch 266/500\n",
            "1/1 - 0s - loss: 0.0308 - mse: 0.0308\n",
            "Epoch 267/500\n",
            "1/1 - 0s - loss: 0.0307 - mse: 0.0307\n",
            "Epoch 268/500\n",
            "1/1 - 0s - loss: 0.0306 - mse: 0.0306\n",
            "Epoch 269/500\n",
            "1/1 - 0s - loss: 0.0304 - mse: 0.0304\n",
            "Epoch 270/500\n",
            "1/1 - 0s - loss: 0.0303 - mse: 0.0303\n",
            "Epoch 271/500\n",
            "1/1 - 0s - loss: 0.0302 - mse: 0.0302\n",
            "Epoch 272/500\n",
            "1/1 - 0s - loss: 0.0300 - mse: 0.0300\n",
            "Epoch 273/500\n",
            "1/1 - 0s - loss: 0.0299 - mse: 0.0299\n",
            "Epoch 274/500\n",
            "1/1 - 0s - loss: 0.0298 - mse: 0.0298\n",
            "Epoch 275/500\n",
            "1/1 - 0s - loss: 0.0297 - mse: 0.0297\n",
            "Epoch 276/500\n",
            "1/1 - 0s - loss: 0.0295 - mse: 0.0295\n",
            "Epoch 277/500\n",
            "1/1 - 0s - loss: 0.0294 - mse: 0.0294\n",
            "Epoch 278/500\n",
            "1/1 - 0s - loss: 0.0293 - mse: 0.0293\n",
            "Epoch 279/500\n",
            "1/1 - 0s - loss: 0.0292 - mse: 0.0292\n",
            "Epoch 280/500\n",
            "1/1 - 0s - loss: 0.0290 - mse: 0.0290\n",
            "Epoch 281/500\n",
            "1/1 - 0s - loss: 0.0289 - mse: 0.0289\n",
            "Epoch 282/500\n",
            "1/1 - 0s - loss: 0.0288 - mse: 0.0288\n",
            "Epoch 283/500\n",
            "1/1 - 0s - loss: 0.0287 - mse: 0.0287\n",
            "Epoch 284/500\n",
            "1/1 - 0s - loss: 0.0286 - mse: 0.0286\n",
            "Epoch 285/500\n",
            "1/1 - 0s - loss: 0.0285 - mse: 0.0285\n",
            "Epoch 286/500\n",
            "1/1 - 0s - loss: 0.0283 - mse: 0.0283\n",
            "Epoch 287/500\n",
            "1/1 - 0s - loss: 0.0282 - mse: 0.0282\n",
            "Epoch 288/500\n",
            "1/1 - 0s - loss: 0.0281 - mse: 0.0281\n",
            "Epoch 289/500\n",
            "1/1 - 0s - loss: 0.0280 - mse: 0.0280\n",
            "Epoch 290/500\n",
            "1/1 - 0s - loss: 0.0279 - mse: 0.0279\n",
            "Epoch 291/500\n",
            "1/1 - 0s - loss: 0.0278 - mse: 0.0278\n",
            "Epoch 292/500\n",
            "1/1 - 0s - loss: 0.0277 - mse: 0.0277\n",
            "Epoch 293/500\n",
            "1/1 - 0s - loss: 0.0276 - mse: 0.0276\n",
            "Epoch 294/500\n",
            "1/1 - 0s - loss: 0.0275 - mse: 0.0275\n",
            "Epoch 295/500\n",
            "1/1 - 0s - loss: 0.0273 - mse: 0.0273\n",
            "Epoch 296/500\n",
            "1/1 - 0s - loss: 0.0272 - mse: 0.0272\n",
            "Epoch 297/500\n",
            "1/1 - 0s - loss: 0.0271 - mse: 0.0271\n",
            "Epoch 298/500\n",
            "1/1 - 0s - loss: 0.0270 - mse: 0.0270\n",
            "Epoch 299/500\n",
            "1/1 - 0s - loss: 0.0269 - mse: 0.0269\n",
            "Epoch 300/500\n",
            "1/1 - 0s - loss: 0.0268 - mse: 0.0268\n",
            "Epoch 301/500\n",
            "1/1 - 0s - loss: 0.0267 - mse: 0.0267\n",
            "Epoch 302/500\n",
            "1/1 - 0s - loss: 0.0266 - mse: 0.0266\n",
            "Epoch 303/500\n",
            "1/1 - 0s - loss: 0.0265 - mse: 0.0265\n",
            "Epoch 304/500\n",
            "1/1 - 0s - loss: 0.0264 - mse: 0.0264\n",
            "Epoch 305/500\n",
            "1/1 - 0s - loss: 0.0263 - mse: 0.0263\n",
            "Epoch 306/500\n",
            "1/1 - 0s - loss: 0.0262 - mse: 0.0262\n",
            "Epoch 307/500\n",
            "1/1 - 0s - loss: 0.0261 - mse: 0.0261\n",
            "Epoch 308/500\n",
            "1/1 - 0s - loss: 0.0260 - mse: 0.0260\n",
            "Epoch 309/500\n",
            "1/1 - 0s - loss: 0.0259 - mse: 0.0259\n",
            "Epoch 310/500\n",
            "1/1 - 0s - loss: 0.0258 - mse: 0.0258\n",
            "Epoch 311/500\n",
            "1/1 - 0s - loss: 0.0257 - mse: 0.0257\n",
            "Epoch 312/500\n",
            "1/1 - 0s - loss: 0.0256 - mse: 0.0256\n",
            "Epoch 313/500\n",
            "1/1 - 0s - loss: 0.0255 - mse: 0.0255\n",
            "Epoch 314/500\n",
            "1/1 - 0s - loss: 0.0255 - mse: 0.0255\n",
            "Epoch 315/500\n",
            "1/1 - 0s - loss: 0.0254 - mse: 0.0254\n",
            "Epoch 316/500\n",
            "1/1 - 0s - loss: 0.0253 - mse: 0.0253\n",
            "Epoch 317/500\n",
            "1/1 - 0s - loss: 0.0252 - mse: 0.0252\n",
            "Epoch 318/500\n",
            "1/1 - 0s - loss: 0.0251 - mse: 0.0251\n",
            "Epoch 319/500\n",
            "1/1 - 0s - loss: 0.0250 - mse: 0.0250\n",
            "Epoch 320/500\n",
            "1/1 - 0s - loss: 0.0249 - mse: 0.0249\n",
            "Epoch 321/500\n",
            "1/1 - 0s - loss: 0.0248 - mse: 0.0248\n",
            "Epoch 322/500\n",
            "1/1 - 0s - loss: 0.0247 - mse: 0.0247\n",
            "Epoch 323/500\n",
            "1/1 - 0s - loss: 0.0246 - mse: 0.0246\n",
            "Epoch 324/500\n",
            "1/1 - 0s - loss: 0.0245 - mse: 0.0245\n",
            "Epoch 325/500\n",
            "1/1 - 0s - loss: 0.0245 - mse: 0.0245\n",
            "Epoch 326/500\n",
            "1/1 - 0s - loss: 0.0244 - mse: 0.0244\n",
            "Epoch 327/500\n",
            "1/1 - 0s - loss: 0.0243 - mse: 0.0243\n",
            "Epoch 328/500\n",
            "1/1 - 0s - loss: 0.0242 - mse: 0.0242\n",
            "Epoch 329/500\n",
            "1/1 - 0s - loss: 0.0241 - mse: 0.0241\n",
            "Epoch 330/500\n",
            "1/1 - 0s - loss: 0.0240 - mse: 0.0240\n",
            "Epoch 331/500\n",
            "1/1 - 0s - loss: 0.0240 - mse: 0.0240\n",
            "Epoch 332/500\n",
            "1/1 - 0s - loss: 0.0239 - mse: 0.0239\n",
            "Epoch 333/500\n",
            "1/1 - 0s - loss: 0.0238 - mse: 0.0238\n",
            "Epoch 334/500\n",
            "1/1 - 0s - loss: 0.0237 - mse: 0.0237\n",
            "Epoch 335/500\n",
            "1/1 - 0s - loss: 0.0236 - mse: 0.0236\n",
            "Epoch 336/500\n",
            "1/1 - 0s - loss: 0.0235 - mse: 0.0235\n",
            "Epoch 337/500\n",
            "1/1 - 0s - loss: 0.0235 - mse: 0.0235\n",
            "Epoch 338/500\n",
            "1/1 - 0s - loss: 0.0234 - mse: 0.0234\n",
            "Epoch 339/500\n",
            "1/1 - 0s - loss: 0.0233 - mse: 0.0233\n",
            "Epoch 340/500\n",
            "1/1 - 0s - loss: 0.0232 - mse: 0.0232\n",
            "Epoch 341/500\n",
            "1/1 - 0s - loss: 0.0231 - mse: 0.0231\n",
            "Epoch 342/500\n",
            "1/1 - 0s - loss: 0.0231 - mse: 0.0231\n",
            "Epoch 343/500\n",
            "1/1 - 0s - loss: 0.0230 - mse: 0.0230\n",
            "Epoch 344/500\n",
            "1/1 - 0s - loss: 0.0229 - mse: 0.0229\n",
            "Epoch 345/500\n",
            "1/1 - 0s - loss: 0.0228 - mse: 0.0228\n",
            "Epoch 346/500\n",
            "1/1 - 0s - loss: 0.0228 - mse: 0.0228\n",
            "Epoch 347/500\n",
            "1/1 - 0s - loss: 0.0227 - mse: 0.0227\n",
            "Epoch 348/500\n",
            "1/1 - 0s - loss: 0.0226 - mse: 0.0226\n",
            "Epoch 349/500\n",
            "1/1 - 0s - loss: 0.0225 - mse: 0.0225\n",
            "Epoch 350/500\n",
            "1/1 - 0s - loss: 0.0225 - mse: 0.0225\n",
            "Epoch 351/500\n",
            "1/1 - 0s - loss: 0.0224 - mse: 0.0224\n",
            "Epoch 352/500\n",
            "1/1 - 0s - loss: 0.0223 - mse: 0.0223\n",
            "Epoch 353/500\n",
            "1/1 - 0s - loss: 0.0222 - mse: 0.0222\n",
            "Epoch 354/500\n",
            "1/1 - 0s - loss: 0.0222 - mse: 0.0222\n",
            "Epoch 355/500\n",
            "1/1 - 0s - loss: 0.0221 - mse: 0.0221\n",
            "Epoch 356/500\n",
            "1/1 - 0s - loss: 0.0220 - mse: 0.0220\n",
            "Epoch 357/500\n",
            "1/1 - 0s - loss: 0.0220 - mse: 0.0220\n",
            "Epoch 358/500\n",
            "1/1 - 0s - loss: 0.0219 - mse: 0.0219\n",
            "Epoch 359/500\n",
            "1/1 - 0s - loss: 0.0218 - mse: 0.0218\n",
            "Epoch 360/500\n",
            "1/1 - 0s - loss: 0.0217 - mse: 0.0217\n",
            "Epoch 361/500\n",
            "1/1 - 0s - loss: 0.0217 - mse: 0.0217\n",
            "Epoch 362/500\n",
            "1/1 - 0s - loss: 0.0216 - mse: 0.0216\n",
            "Epoch 363/500\n",
            "1/1 - 0s - loss: 0.0215 - mse: 0.0215\n",
            "Epoch 364/500\n",
            "1/1 - 0s - loss: 0.0215 - mse: 0.0215\n",
            "Epoch 365/500\n",
            "1/1 - 0s - loss: 0.0214 - mse: 0.0214\n",
            "Epoch 366/500\n",
            "1/1 - 0s - loss: 0.0213 - mse: 0.0213\n",
            "Epoch 367/500\n",
            "1/1 - 0s - loss: 0.0213 - mse: 0.0213\n",
            "Epoch 368/500\n",
            "1/1 - 0s - loss: 0.0212 - mse: 0.0212\n",
            "Epoch 369/500\n",
            "1/1 - 0s - loss: 0.0211 - mse: 0.0211\n",
            "Epoch 370/500\n",
            "1/1 - 0s - loss: 0.0211 - mse: 0.0211\n",
            "Epoch 371/500\n",
            "1/1 - 0s - loss: 0.0210 - mse: 0.0210\n",
            "Epoch 372/500\n",
            "1/1 - 0s - loss: 0.0209 - mse: 0.0209\n",
            "Epoch 373/500\n",
            "1/1 - 0s - loss: 0.0209 - mse: 0.0209\n",
            "Epoch 374/500\n",
            "1/1 - 0s - loss: 0.0208 - mse: 0.0208\n",
            "Epoch 375/500\n",
            "1/1 - 0s - loss: 0.0208 - mse: 0.0208\n",
            "Epoch 376/500\n",
            "1/1 - 0s - loss: 0.0207 - mse: 0.0207\n",
            "Epoch 377/500\n",
            "1/1 - 0s - loss: 0.0206 - mse: 0.0206\n",
            "Epoch 378/500\n",
            "1/1 - 0s - loss: 0.0206 - mse: 0.0206\n",
            "Epoch 379/500\n",
            "1/1 - 0s - loss: 0.0205 - mse: 0.0205\n",
            "Epoch 380/500\n",
            "1/1 - 0s - loss: 0.0204 - mse: 0.0204\n",
            "Epoch 381/500\n",
            "1/1 - 0s - loss: 0.0204 - mse: 0.0204\n",
            "Epoch 382/500\n",
            "1/1 - 0s - loss: 0.0203 - mse: 0.0203\n",
            "Epoch 383/500\n",
            "1/1 - 0s - loss: 0.0203 - mse: 0.0203\n",
            "Epoch 384/500\n",
            "1/1 - 0s - loss: 0.0202 - mse: 0.0202\n",
            "Epoch 385/500\n",
            "1/1 - 0s - loss: 0.0201 - mse: 0.0201\n",
            "Epoch 386/500\n",
            "1/1 - 0s - loss: 0.0201 - mse: 0.0201\n",
            "Epoch 387/500\n",
            "1/1 - 0s - loss: 0.0200 - mse: 0.0200\n",
            "Epoch 388/500\n",
            "1/1 - 0s - loss: 0.0200 - mse: 0.0200\n",
            "Epoch 389/500\n",
            "1/1 - 0s - loss: 0.0199 - mse: 0.0199\n",
            "Epoch 390/500\n",
            "1/1 - 0s - loss: 0.0198 - mse: 0.0198\n",
            "Epoch 391/500\n",
            "1/1 - 0s - loss: 0.0198 - mse: 0.0198\n",
            "Epoch 392/500\n",
            "1/1 - 0s - loss: 0.0197 - mse: 0.0197\n",
            "Epoch 393/500\n",
            "1/1 - 0s - loss: 0.0197 - mse: 0.0197\n",
            "Epoch 394/500\n",
            "1/1 - 0s - loss: 0.0196 - mse: 0.0196\n",
            "Epoch 395/500\n",
            "1/1 - 0s - loss: 0.0196 - mse: 0.0196\n",
            "Epoch 396/500\n",
            "1/1 - 0s - loss: 0.0195 - mse: 0.0195\n",
            "Epoch 397/500\n",
            "1/1 - 0s - loss: 0.0194 - mse: 0.0194\n",
            "Epoch 398/500\n",
            "1/1 - 0s - loss: 0.0194 - mse: 0.0194\n",
            "Epoch 399/500\n",
            "1/1 - 0s - loss: 0.0193 - mse: 0.0193\n",
            "Epoch 400/500\n",
            "1/1 - 0s - loss: 0.0193 - mse: 0.0193\n",
            "Epoch 401/500\n",
            "1/1 - 0s - loss: 0.0192 - mse: 0.0192\n",
            "Epoch 402/500\n",
            "1/1 - 0s - loss: 0.0192 - mse: 0.0192\n",
            "Epoch 403/500\n",
            "1/1 - 0s - loss: 0.0191 - mse: 0.0191\n",
            "Epoch 404/500\n",
            "1/1 - 0s - loss: 0.0191 - mse: 0.0191\n",
            "Epoch 405/500\n",
            "1/1 - 0s - loss: 0.0190 - mse: 0.0190\n",
            "Epoch 406/500\n",
            "1/1 - 0s - loss: 0.0190 - mse: 0.0190\n",
            "Epoch 407/500\n",
            "1/1 - 0s - loss: 0.0189 - mse: 0.0189\n",
            "Epoch 408/500\n",
            "1/1 - 0s - loss: 0.0188 - mse: 0.0188\n",
            "Epoch 409/500\n",
            "1/1 - 0s - loss: 0.0188 - mse: 0.0188\n",
            "Epoch 410/500\n",
            "1/1 - 0s - loss: 0.0187 - mse: 0.0187\n",
            "Epoch 411/500\n",
            "1/1 - 0s - loss: 0.0187 - mse: 0.0187\n",
            "Epoch 412/500\n",
            "1/1 - 0s - loss: 0.0186 - mse: 0.0186\n",
            "Epoch 413/500\n",
            "1/1 - 0s - loss: 0.0186 - mse: 0.0186\n",
            "Epoch 414/500\n",
            "1/1 - 0s - loss: 0.0185 - mse: 0.0185\n",
            "Epoch 415/500\n",
            "1/1 - 0s - loss: 0.0185 - mse: 0.0185\n",
            "Epoch 416/500\n",
            "1/1 - 0s - loss: 0.0184 - mse: 0.0184\n",
            "Epoch 417/500\n",
            "1/1 - 0s - loss: 0.0184 - mse: 0.0184\n",
            "Epoch 418/500\n",
            "1/1 - 0s - loss: 0.0183 - mse: 0.0183\n",
            "Epoch 419/500\n",
            "1/1 - 0s - loss: 0.0183 - mse: 0.0183\n",
            "Epoch 420/500\n",
            "1/1 - 0s - loss: 0.0182 - mse: 0.0182\n",
            "Epoch 421/500\n",
            "1/1 - 0s - loss: 0.0182 - mse: 0.0182\n",
            "Epoch 422/500\n",
            "1/1 - 0s - loss: 0.0181 - mse: 0.0181\n",
            "Epoch 423/500\n",
            "1/1 - 0s - loss: 0.0181 - mse: 0.0181\n",
            "Epoch 424/500\n",
            "1/1 - 0s - loss: 0.0180 - mse: 0.0180\n",
            "Epoch 425/500\n",
            "1/1 - 0s - loss: 0.0180 - mse: 0.0180\n",
            "Epoch 426/500\n",
            "1/1 - 0s - loss: 0.0179 - mse: 0.0179\n",
            "Epoch 427/500\n",
            "1/1 - 0s - loss: 0.0179 - mse: 0.0179\n",
            "Epoch 428/500\n",
            "1/1 - 0s - loss: 0.0178 - mse: 0.0178\n",
            "Epoch 429/500\n",
            "1/1 - 0s - loss: 0.0178 - mse: 0.0178\n",
            "Epoch 430/500\n",
            "1/1 - 0s - loss: 0.0177 - mse: 0.0177\n",
            "Epoch 431/500\n",
            "1/1 - 0s - loss: 0.0177 - mse: 0.0177\n",
            "Epoch 432/500\n",
            "1/1 - 0s - loss: 0.0177 - mse: 0.0177\n",
            "Epoch 433/500\n",
            "1/1 - 0s - loss: 0.0176 - mse: 0.0176\n",
            "Epoch 434/500\n",
            "1/1 - 0s - loss: 0.0176 - mse: 0.0176\n",
            "Epoch 435/500\n",
            "1/1 - 0s - loss: 0.0175 - mse: 0.0175\n",
            "Epoch 436/500\n",
            "1/1 - 0s - loss: 0.0175 - mse: 0.0175\n",
            "Epoch 437/500\n",
            "1/1 - 0s - loss: 0.0174 - mse: 0.0174\n",
            "Epoch 438/500\n",
            "1/1 - 0s - loss: 0.0174 - mse: 0.0174\n",
            "Epoch 439/500\n",
            "1/1 - 0s - loss: 0.0173 - mse: 0.0173\n",
            "Epoch 440/500\n",
            "1/1 - 0s - loss: 0.0173 - mse: 0.0173\n",
            "Epoch 441/500\n",
            "1/1 - 0s - loss: 0.0172 - mse: 0.0172\n",
            "Epoch 442/500\n",
            "1/1 - 0s - loss: 0.0172 - mse: 0.0172\n",
            "Epoch 443/500\n",
            "1/1 - 0s - loss: 0.0172 - mse: 0.0172\n",
            "Epoch 444/500\n",
            "1/1 - 0s - loss: 0.0171 - mse: 0.0171\n",
            "Epoch 445/500\n",
            "1/1 - 0s - loss: 0.0171 - mse: 0.0171\n",
            "Epoch 446/500\n",
            "1/1 - 0s - loss: 0.0170 - mse: 0.0170\n",
            "Epoch 447/500\n",
            "1/1 - 0s - loss: 0.0170 - mse: 0.0170\n",
            "Epoch 448/500\n",
            "1/1 - 0s - loss: 0.0169 - mse: 0.0169\n",
            "Epoch 449/500\n",
            "1/1 - 0s - loss: 0.0169 - mse: 0.0169\n",
            "Epoch 450/500\n",
            "1/1 - 0s - loss: 0.0169 - mse: 0.0169\n",
            "Epoch 451/500\n",
            "1/1 - 0s - loss: 0.0168 - mse: 0.0168\n",
            "Epoch 452/500\n",
            "1/1 - 0s - loss: 0.0168 - mse: 0.0168\n",
            "Epoch 453/500\n",
            "1/1 - 0s - loss: 0.0167 - mse: 0.0167\n",
            "Epoch 454/500\n",
            "1/1 - 0s - loss: 0.0167 - mse: 0.0167\n",
            "Epoch 455/500\n",
            "1/1 - 0s - loss: 0.0166 - mse: 0.0166\n",
            "Epoch 456/500\n",
            "1/1 - 0s - loss: 0.0166 - mse: 0.0166\n",
            "Epoch 457/500\n",
            "1/1 - 0s - loss: 0.0166 - mse: 0.0166\n",
            "Epoch 458/500\n",
            "1/1 - 0s - loss: 0.0165 - mse: 0.0165\n",
            "Epoch 459/500\n",
            "1/1 - 0s - loss: 0.0165 - mse: 0.0165\n",
            "Epoch 460/500\n",
            "1/1 - 0s - loss: 0.0164 - mse: 0.0164\n",
            "Epoch 461/500\n",
            "1/1 - 0s - loss: 0.0164 - mse: 0.0164\n",
            "Epoch 462/500\n",
            "1/1 - 0s - loss: 0.0164 - mse: 0.0164\n",
            "Epoch 463/500\n",
            "1/1 - 0s - loss: 0.0163 - mse: 0.0163\n",
            "Epoch 464/500\n",
            "1/1 - 0s - loss: 0.0163 - mse: 0.0163\n",
            "Epoch 465/500\n",
            "1/1 - 0s - loss: 0.0162 - mse: 0.0162\n",
            "Epoch 466/500\n",
            "1/1 - 0s - loss: 0.0162 - mse: 0.0162\n",
            "Epoch 467/500\n",
            "1/1 - 0s - loss: 0.0162 - mse: 0.0162\n",
            "Epoch 468/500\n",
            "1/1 - 0s - loss: 0.0161 - mse: 0.0161\n",
            "Epoch 469/500\n",
            "1/1 - 0s - loss: 0.0161 - mse: 0.0161\n",
            "Epoch 470/500\n",
            "1/1 - 0s - loss: 0.0160 - mse: 0.0160\n",
            "Epoch 471/500\n",
            "1/1 - 0s - loss: 0.0160 - mse: 0.0160\n",
            "Epoch 472/500\n",
            "1/1 - 0s - loss: 0.0160 - mse: 0.0160\n",
            "Epoch 473/500\n",
            "1/1 - 0s - loss: 0.0159 - mse: 0.0159\n",
            "Epoch 474/500\n",
            "1/1 - 0s - loss: 0.0159 - mse: 0.0159\n",
            "Epoch 475/500\n",
            "1/1 - 0s - loss: 0.0158 - mse: 0.0158\n",
            "Epoch 476/500\n",
            "1/1 - 0s - loss: 0.0158 - mse: 0.0158\n",
            "Epoch 477/500\n",
            "1/1 - 0s - loss: 0.0158 - mse: 0.0158\n",
            "Epoch 478/500\n",
            "1/1 - 0s - loss: 0.0157 - mse: 0.0157\n",
            "Epoch 479/500\n",
            "1/1 - 0s - loss: 0.0157 - mse: 0.0157\n",
            "Epoch 480/500\n",
            "1/1 - 0s - loss: 0.0157 - mse: 0.0157\n",
            "Epoch 481/500\n",
            "1/1 - 0s - loss: 0.0156 - mse: 0.0156\n",
            "Epoch 482/500\n",
            "1/1 - 0s - loss: 0.0156 - mse: 0.0156\n",
            "Epoch 483/500\n",
            "1/1 - 0s - loss: 0.0155 - mse: 0.0155\n",
            "Epoch 484/500\n",
            "1/1 - 0s - loss: 0.0155 - mse: 0.0155\n",
            "Epoch 485/500\n",
            "1/1 - 0s - loss: 0.0155 - mse: 0.0155\n",
            "Epoch 486/500\n",
            "1/1 - 0s - loss: 0.0154 - mse: 0.0154\n",
            "Epoch 487/500\n",
            "1/1 - 0s - loss: 0.0154 - mse: 0.0154\n",
            "Epoch 488/500\n",
            "1/1 - 0s - loss: 0.0154 - mse: 0.0154\n",
            "Epoch 489/500\n",
            "1/1 - 0s - loss: 0.0153 - mse: 0.0153\n",
            "Epoch 490/500\n",
            "1/1 - 0s - loss: 0.0153 - mse: 0.0153\n",
            "Epoch 491/500\n",
            "1/1 - 0s - loss: 0.0153 - mse: 0.0153\n",
            "Epoch 492/500\n",
            "1/1 - 0s - loss: 0.0152 - mse: 0.0152\n",
            "Epoch 493/500\n",
            "1/1 - 0s - loss: 0.0152 - mse: 0.0152\n",
            "Epoch 494/500\n",
            "1/1 - 0s - loss: 0.0152 - mse: 0.0152\n",
            "Epoch 495/500\n",
            "1/1 - 0s - loss: 0.0151 - mse: 0.0151\n",
            "Epoch 496/500\n",
            "1/1 - 0s - loss: 0.0151 - mse: 0.0151\n",
            "Epoch 497/500\n",
            "1/1 - 0s - loss: 0.0151 - mse: 0.0151\n",
            "Epoch 498/500\n",
            "1/1 - 0s - loss: 0.0150 - mse: 0.0150\n",
            "Epoch 499/500\n",
            "1/1 - 0s - loss: 0.0150 - mse: 0.0150\n",
            "Epoch 500/500\n",
            "1/1 - 0s - loss: 0.0149 - mse: 0.0149\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LFqwOkoGK0O"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "\n",
        "x_train = x_train.astype(np.float32) / 255.\n",
        "x_test = x_test.astype(np.float32) / 255.\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeHBQ4LfHVCk"
      },
      "source": [
        "n_input = 784\n",
        "n_hidden = 1024\n",
        "n_output=10\n",
        "\n",
        "mlp = Sequential()\n",
        "mlp.add(Dense(units=n_hidden,\n",
        "              activation='tanh',\n",
        "              input_shape=(n_input, ),\n",
        "              kernel_initializer='random_uniform',\n",
        "              bias_initializer='zeros'))\n",
        "mlp.add(Dense(units = n_output,\n",
        "              activation='tanh',\n",
        "              kernel_initializer='random_uniform',\n",
        "              bias_initializer='zeros'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "5VLBtO-dH4wV",
        "outputId": "a2e6be5a-0383-424b-8b05-7d0c07c1bdfd"
      },
      "source": [
        "mlp.compile(loss='mean_squared_error',\n",
        "            optimizer=Adam(learning_rate=0.001),\n",
        "            metrics=['accuracy'])\n",
        "hist = mlp.fit(x_train, y_train, batch_size=128, epochs=30, validation_data=(x_test, y_test), verbose=2)\n",
        "res = mlp.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"accuracy = {res[1] * 100}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "469/469 - 6s - loss: 0.0432 - accuracy: 0.8409 - val_loss: 0.0280 - val_accuracy: 0.9144\n",
            "Epoch 2/30\n",
            "469/469 - 6s - loss: 0.0226 - accuracy: 0.9272 - val_loss: 0.0188 - val_accuracy: 0.9418\n",
            "Epoch 3/30\n",
            "469/469 - 6s - loss: 0.0166 - accuracy: 0.9469 - val_loss: 0.0146 - val_accuracy: 0.9519\n",
            "Epoch 4/30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-c208c8532f1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             metrics=['accuracy'])\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"accuracy = {res[1] * 100}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNo3Ldw3IPKC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}